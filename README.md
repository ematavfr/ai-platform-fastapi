# AI Platform FastAPI

## ğŸš€ Plateforme d'Intelligence Artificielle d'Entreprise

Cette plateforme permet l'intÃ©gration complÃ¨te de l'IA en entreprise en utilisant **FastAPI** comme framework principal, avec une architecture microservices moderne et des principes DevOps.

## ğŸ“‹ Table des MatiÃ¨res

- [Architecture](#architecture)
- [Technologies](#technologies)
- [DÃ©marrage Rapide](#dÃ©marrage-rapide)
- [Services](#services)
- [API Documentation](#api-documentation)
- [Monitoring](#monitoring)
- [DevOps & DÃ©ploiement](#devops--dÃ©ploiement)
- [Exemples d'Utilisation](#exemples-dutilisation)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚â”€â”€â”€â”€â–¶â”‚   Nginx Gateway â”‚â”€â”€â”€â”€â–¶â”‚   API Server    â”‚
â”‚   (React)       â”‚     â”‚   (Load Balancer)â”‚     â”‚   (FastAPI)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                                                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ML Service    â”‚â—€â”€â”€â”€â”€â”‚   PostgreSQL    â”‚â”€â”€â”€â”€â–¶â”‚   Redis Cache   â”‚
â”‚   (FastAPI)     â”‚     â”‚   (Database)    â”‚     â”‚   & Queues      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                               â”‚
          â–¼                                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MinIO S3      â”‚     â”‚   Celery Worker â”‚     â”‚   Monitoring    â”‚
â”‚   (Storage)     â”‚     â”‚   (Async Tasks) â”‚     â”‚   (Prometheus)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Technologies

### Backend
- **FastAPI** - Framework web moderne et performant
- **SQLAlchemy** - ORM avec support async
- **PostgreSQL** - Base de donnÃ©es relationnelle
- **Redis** - Cache et message broker
- **Celery** - TÃ¢ches asynchrones
- **MinIO** - Stockage S3-compatible

### ML & IA
- **Scikit-learn** - Machine Learning classique
- **XGBoost/LightGBM** - Gradient boosting
- **TensorFlow/PyTorch** - Deep Learning (extensible)
- **Pandas/NumPy** - Traitement de donnÃ©es

### DevOps & Monitoring
- **Docker & Docker Compose** - Containerisation
- **Nginx** - Load balancer et reverse proxy
- **Prometheus & Grafana** - Monitoring et mÃ©triques
- **ELK Stack** - Logs centralisÃ©s

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis
- Docker et Docker Compose
- Git
- 8GB RAM minimum

### Installation

1. **Cloner le repository**
```bash
git clone git@github.com:ematavfr/ai-platform-fastapi.git
cd ai-platform-fastapi
```

2. **Lancer l'infrastructure complÃ¨te**
```bash
docker-compose up -d
```

3. **VÃ©rifier que tous les services sont actifs**
```bash
docker-compose ps
```

### ğŸŒ AccÃ¨s aux Services

| Service | URL | Description |
|---------|-----|-------------|
| API Documentation | http://localhost:8000/docs | Swagger UI de l'API principale |
| ML Service Docs | http://localhost:8001/docs | Documentation du service ML |
| Frontend | http://localhost:3000 | Interface utilisateur React |
| Grafana | http://localhost:3001 | Dashboards (admin/admin123) |
| Flower (Celery) | http://localhost:5555 | Monitoring des tÃ¢ches |
| MinIO Console | http://localhost:9001 | Interface de stockage |
| Kibana | http://localhost:5601 | Visualisation des logs |

## ğŸ“Š Services

### 1. API Server (Port 8000)
Service principal gÃ©rant :
- **Authentification JWT** avec refresh tokens
- **Gestion des utilisateurs** et permissions
- **Projets ML** et cycles de vie
- **Datasets** avec upload et validation
- **ModÃ¨les ML** avec versioning
- **API REST complÃ¨te** avec documentation automatique

**FonctionnalitÃ©s clÃ©s :**
- Rate limiting intelligent
- Validation Pydantic
- Gestion d'erreurs centralisÃ©e
- MÃ©triques Prometheus
- TÃ¢ches asynchrones Celery

### 2. ML Service (Port 8001)
Service spÃ©cialisÃ© pour :
- **PrÃ©dictions temps rÃ©el** avec cache Redis
- **Chargement dynamique** des modÃ¨les
- **Preprocessing/Postprocessing** configurable
- **PrÃ©dictions en lot** optimisÃ©es
- **Gestion mÃ©moire** des modÃ¨les

**Optimisations :**
- LRU cache des modÃ¨les
- Pool de connexions
- MÃ©triques de performance
- Fallback graceful

### 3. Base de DonnÃ©es & Stockage
- **PostgreSQL** : MÃ©tadonnÃ©es, utilisateurs, projets
- **Redis** : Cache, sessions, queues Celery
- **MinIO** : ModÃ¨les ML, datasets, artifacts

## ğŸ“š API Documentation

### Authentification
```bash
# Inscription
curl -X POST "http://localhost:8000/api/v1/auth/register" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "user@example.com",
    "username": "newuser",
    "password": "securepassword123",
    "full_name": "New User"
  }'

# Connexion
curl -X POST "http://localhost:8000/api/v1/auth/token" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "username=newuser&password=securepassword123"
```

### CrÃ©ation d'un ModÃ¨le
```bash
# CrÃ©er un projet
curl -X POST "http://localhost:8000/api/v1/projects/" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Classification Project",
    "description": "Projet de classification d'images"
  }'

# CrÃ©er un modÃ¨le
curl -X POST "http://localhost:8000/api/v1/models/" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Random Forest Classifier",
    "model_type": "classification",
    "framework": "scikit-learn",
    "project_id": "PROJECT_UUID"
  }'
```

### PrÃ©dictions
```bash
# PrÃ©diction simple
curl -X POST "http://localhost:8001/predict/model_id" \
  -H "Content-Type: application/json" \
  -d '{
    "input_data": {"feature1": 1.5, "feature2": 2.3},
    "return_probabilities": true
  }'

# PrÃ©diction en lot
curl -X POST "http://localhost:8001/predict/model_id/batch" \
  -H "Content-Type: application/json" \
  -d '{
    "inputs": [
      {"feature1": 1.5, "feature2": 2.3},
      {"feature1": 2.1, "feature2": 1.8}
    ]
  }'
```

## ğŸ“ˆ Monitoring

### MÃ©triques Disponibles
- **Performance API** : Latence, throughput, erreurs
- **Utilisation ML** : PrÃ©dictions/sec, cache hit rate
- **Infrastructure** : CPU, mÃ©moire, stockage
- **Business** : Utilisateurs actifs, modÃ¨les dÃ©ployÃ©s

### Dashboards Grafana
1. **API Performance** - MÃ©triques temps rÃ©el de l'API
2. **ML Service** - Performance des prÃ©dictions
3. **Infrastructure** - SantÃ© des services
4. **Business Intelligence** - KPIs mÃ©tier

## ğŸ”§ DevOps & DÃ©ploiement

### Variables d'Environnement
CrÃ©er un fichier `.env` :
```bash
# API Server
DATABASE_URL=postgresql://postgres:postgres123@postgres:5432/ai_platform
REDIS_URL=redis://redis:6379
SECRET_KEY=your-super-secret-key-change-in-production
JWT_SECRET_KEY=jwt-secret-key

# MinIO
MINIO_ENDPOINT=minio:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin123

# Environment
ENVIRONMENT=production
DEBUG=false
```

### DÃ©ploiement Production
Pour un dÃ©ploiement en production :

1. **Kubernetes** (recommandÃ©)
```bash
# Utiliser les manifests Kubernetes (Ã  crÃ©er)
kubectl apply -f k8s/
```

2. **Docker Swarm**
```bash
docker stack deploy -c docker-compose.prod.yml ai-platform
```

### SÃ©curitÃ©
- SSL/TLS terminaison sur Nginx
- Secrets gÃ©rÃ©s via Docker Secrets ou Kubernetes Secrets
- Rate limiting et protection DDoS
- Authentification JWT sÃ©curisÃ©e
- Validation stricte des inputs

## ğŸ§ª Exemples d'Utilisation

### 1. Classification d'Images
```python
import requests

# Upload d'un dataset
files = {'file': open('dataset.csv', 'rb')}
response = requests.post(
    'http://localhost:8000/api/v1/datasets/',
    files=files,
    headers={'Authorization': 'Bearer YOUR_TOKEN'}
)

# EntraÃ®nement d'un modÃ¨le
model_data = {
    "name": "Image Classifier",
    "model_type": "classification",
    "framework": "tensorflow",
    "dataset_id": response.json()["id"]
}
model_response = requests.post(
    'http://localhost:8000/api/v1/models/',
    json=model_data,
    headers={'Authorization': 'Bearer YOUR_TOKEN'}
)
```

### 2. PrÃ©diction en Temps RÃ©el
```python
# PrÃ©diction
prediction_data = {
    "input_data": {
        "feature1": 1.5,
        "feature2": 2.3,
        "feature3": 0.8
    },
    "return_probabilities": True
}

response = requests.post(
    f'http://localhost:8001/predict/{model_id}',
    json=prediction_data
)

result = response.json()
print(f"PrÃ©diction: {result['prediction']}")
print(f"Confiance: {result['confidence_score']}")
```

### 3. Pipeline ML Complet
```python
# Workflow complet automatisÃ©
class MLPipeline:
    def __init__(self, api_base_url, token):
        self.api_url = api_base_url
        self.headers = {'Authorization': f'Bearer {token}'}
    
    def create_project(self, name, description):
        """CrÃ©er un nouveau projet"""
        return requests.post(
            f'{self.api_url}/projects/',
            json={'name': name, 'description': description},
            headers=self.headers
        ).json()
    
    def upload_dataset(self, file_path, project_id):
        """Upload dataset"""
        files = {'file': open(file_path, 'rb')}
        data = {'project_id': project_id}
        return requests.post(
            f'{self.api_url}/datasets/',
            files=files,
            data=data,
            headers=self.headers
        ).json()
    
    def train_model(self, model_config):
        """EntraÃ®ner un modÃ¨le"""
        return requests.post(
            f'{self.api_url}/models/',
            json=model_config,
            headers=self.headers
        ).json()
    
    def deploy_model(self, model_id):
        """DÃ©ployer un modÃ¨le"""
        return requests.post(
            f'{self.api_url}/models/{model_id}/deploy',
            headers=self.headers
        ).json()
```

## ğŸ” Cas d'Usage Entreprise

### 1. Ã‰quipe Data Science
- Upload et versioning des datasets
- ExpÃ©rimentation avec diffÃ©rents algorithmes
- Suivi des mÃ©triques de performance
- Collaboration sur les projets

### 2. Ã‰quipe DÃ©veloppement
- API REST standardisÃ©e
- IntÃ©gration facile dans les applications
- Documentation automatique
- Tests et monitoring

### 3. Ã‰quipe Ops
- DÃ©ploiement containerisÃ©
- Monitoring complet
- Gestion des ressources
- SÃ©curitÃ© et compliance

## ğŸš¨ Troubleshooting

### ProblÃ¨mes Courants

**Services qui ne dÃ©marrent pas**
```bash
# VÃ©rifier les logs
docker-compose logs api-server
docker-compose logs ml-service

# RedÃ©marrer un service
docker-compose restart api-server
```

**ProblÃ¨mes de base de donnÃ©es**
```bash
# RÃ©initialiser la DB
docker-compose down -v
docker-compose up -d postgres
```

**ProblÃ¨mes de cache Redis**
```bash
# Vider le cache
docker-compose exec redis redis-cli FLUSHALL
```

## ğŸ¤ Contributing

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ“ Support

- ğŸ“§ Email: support@aiplatform.com
- ğŸ“– Documentation: [docs.aiplatform.com](https://docs.aiplatform.com)
- ğŸ› Issues: [GitHub Issues](https://github.com/ematavfr/ai-platform-fastapi/issues)

---

**DÃ©veloppÃ© avec â¤ï¸ pour l'intÃ©gration de l'IA en entreprise**