#!/usr/bin/env python3
"""
Exemple d'utilisation du client Python pour l'AI Platform FastAPI

Cet exemple montre comment :
1. S'authentifier auprÃ¨s de l'API
2. CrÃ©er un projet ML
3. Uploader un dataset  
4. CrÃ©er et entraÃ®ner un modÃ¨le
5. Effectuer des prÃ©dictions
6. Monitorer les performances
"""

import requests
import json
import time
import pandas as pd
from typing import Optional, Dict, Any
import logging

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AIPlatformClient:
    """Client Python pour l'AI Platform FastAPI"""
    
    def __init__(self, api_base_url: str = "http://localhost:8000", ml_base_url: str = "http://localhost:8001"):
        self.api_url = api_base_url
        self.ml_url = ml_base_url
        self.token = None
        self.headers = {"Content-Type": "application/json"}
    
    def register(self, email: str, username: str, password: str, full_name: str = None) -> Dict[str, Any]:
        """Inscription d'un nouvel utilisateur"""
        data = {
            "email": email,
            "username": username,
            "password": password,
            "full_name": full_name or username
        }
        
        response = requests.post(f"{self.api_url}/api/v1/auth/register", json=data)
        
        if response.status_code == 201:
            logger.info(f"âœ… User {username} registered successfully")
            return response.json()
        else:
            logger.error(f"âŒ Registration failed: {response.text}")
            response.raise_for_status()
    
    def login(self, username: str, password: str) -> str:
        """Connexion et rÃ©cupÃ©ration du token JWT"""
        data = {
            "username": username,
            "password": password
        }
        
        response = requests.post(
            f"{self.api_url}/api/v1/auth/token",
            data=data,
            headers={"Content-Type": "application/x-www-form-urlencoded"}
        )
        
        if response.status_code == 200:
            token_data = response.json()
            self.token = token_data["access_token"]
            self.headers["Authorization"] = f"Bearer {self.token}"
            logger.info("âœ… Login successful")
            return self.token
        else:
            logger.error(f"âŒ Login failed: {response.text}")
            response.raise_for_status()
    
    def get_profile(self) -> Dict[str, Any]:
        """RÃ©cupÃ¨re le profil de l'utilisateur connectÃ©"""
        if not self.token:
            raise ValueError("Must be logged in")
        
        response = requests.get(f"{self.api_url}/api/v1/auth/me", headers=self.headers)
        response.raise_for_status()
        return response.json()
    
    def create_project(self, name: str, description: str = None, tags: list = None) -> Dict[str, Any]:
        """CrÃ©e un nouveau projet ML"""
        data = {
            "name": name,
            "description": description or f"Project {name}",
            "tags": tags or []
        }
        
        response = requests.post(f"{self.api_url}/api/v1/projects/", json=data, headers=self.headers)
        
        if response.status_code == 201:
            project = response.json()
            logger.info(f"âœ… Project '{name}' created with ID: {project.get('id')}")
            return project
        else:
            logger.error(f"âŒ Project creation failed: {response.text}")
            response.raise_for_status()
    
    def upload_dataset(self, file_path: str, name: str, description: str = None, project_id: str = None) -> Dict[str, Any]:
        """Upload un dataset"""
        with open(file_path, 'rb') as f:
            files = {'file': (file_path, f, 'text/csv')}
            data = {
                "name": name,
                "description": description or f"Dataset {name}",
                "project_id": project_id
            }
            
            # Retirer l'Authorization du header pour cette requÃªte multipart
            headers = {"Authorization": self.headers["Authorization"]}
            
            response = requests.post(
                f"{self.api_url}/api/v1/datasets/",
                files=files,
                data=data,
                headers=headers
            )
        
        if response.status_code == 201:
            dataset = response.json()
            logger.info(f"âœ… Dataset '{name}' uploaded with ID: {dataset.get('id')}")
            return dataset
        else:
            logger.error(f"âŒ Dataset upload failed: {response.text}")
            response.raise_for_status()
    
    def create_model(self, name: str, model_type: str, framework: str = "scikit-learn", 
                    project_id: str = None, dataset_id: str = None, **kwargs) -> Dict[str, Any]:
        """CrÃ©e un nouveau modÃ¨le ML"""
        data = {
            "name": name,
            "model_type": model_type,
            "framework": framework,
            "project_id": project_id,
            "dataset_id": dataset_id,
            **kwargs
        }
        
        response = requests.post(f"{self.api_url}/api/v1/models/", json=data, headers=self.headers)
        
        if response.status_code == 201:
            model = response.json()
            logger.info(f"âœ… Model '{name}' created with ID: {model.get('id')}")
            return model
        else:
            logger.error(f"âŒ Model creation failed: {response.text}")
            response.raise_for_status()
    
    def deploy_model(self, model_id: str, config: Dict[str, Any] = None) -> Dict[str, Any]:
        """DÃ©ploie un modÃ¨le pour les prÃ©dictions"""
        response = requests.post(
            f"{self.api_url}/api/v1/models/{model_id}/deploy",
            json=config or {},
            headers=self.headers
        )
        
        if response.status_code == 200:
            result = response.json()
            logger.info(f"âœ… Model {model_id} deployment started")
            return result
        else:
            logger.error(f"âŒ Model deployment failed: {response.text}")
            response.raise_for_status()
    
    def predict(self, model_id: str, input_data: Dict[str, Any], return_probabilities: bool = False) -> Dict[str, Any]:
        """Effectue une prÃ©diction"""
        data = {
            "input_data": input_data,
            "return_probabilities": return_probabilities
        }
        
        response = requests.post(f"{self.ml_url}/predict/{model_id}", json=data)
        
        if response.status_code == 200:
            result = response.json()
            logger.info(f"âœ… Prediction completed in {result.get('processing_time', 0):.2f}ms")
            return result
        else:
            logger.error(f"âŒ Prediction failed: {response.text}")
            response.raise_for_status()
    
    def batch_predict(self, model_id: str, inputs: list, return_probabilities: bool = False) -> Dict[str, Any]:
        """Effectue des prÃ©dictions en lot"""
        data = {
            "inputs": inputs,
            "return_probabilities": return_probabilities
        }
        
        response = requests.post(f"{self.ml_url}/predict/{model_id}/batch", json=data)
        
        if response.status_code == 200:
            result = response.json()
            logger.info(f"âœ… Batch prediction completed: {len(inputs)} predictions in {result.get('total_processing_time', 0):.2f}ms")
            return result
        else:
            logger.error(f"âŒ Batch prediction failed: {response.text}")
            response.raise_for_status()
    
    def get_ml_metrics(self) -> Dict[str, Any]:
        """RÃ©cupÃ¨re les mÃ©triques du service ML"""
        response = requests.get(f"{self.ml_url}/metrics")
        response.raise_for_status()
        return response.json()
    
    def check_health(self) -> Dict[str, bool]:
        """VÃ©rifie la santÃ© des services"""
        health = {"api": False, "ml": False}
        
        try:
            api_response = requests.get(f"{self.api_url}/health", timeout=5)
            health["api"] = api_response.status_code == 200
        except:
            pass
        
        try:
            ml_response = requests.get(f"{self.ml_url}/health", timeout=5)
            health["ml"] = ml_response.status_code == 200
        except:
            pass
        
        return health

def create_sample_dataset() -> str:
    """CrÃ©e un dataset d'exemple pour les tests"""
    import numpy as np
    
    # GÃ©nÃ©rer des donnÃ©es d'exemple
    np.random.seed(42)
    n_samples = 1000
    
    data = {
        'feature1': np.random.normal(0, 1, n_samples),
        'feature2': np.random.normal(1, 1.5, n_samples),
        'feature3': np.random.uniform(-2, 2, n_samples),
        'feature4': np.random.exponential(1, n_samples),
        'target': np.random.choice([0, 1], n_samples, p=[0.6, 0.4])
    }
    
    df = pd.DataFrame(data)
    filename = "/tmp/sample_dataset.csv"
    df.to_csv(filename, index=False)
    
    logger.info(f"âœ… Sample dataset created: {filename}")
    return filename

def main():
    """Exemple d'utilisation complÃ¨te de l'API"""
    
    print("ğŸš€ AI Platform FastAPI - Exemple d'utilisation")
    print("=" * 50)
    
    # Initialiser le client
    client = AIPlatformClient()
    
    # 1. VÃ©rifier la santÃ© des services
    print("\n1. ğŸ¥ Health Check")
    health = client.check_health()
    print(f"   API Server: {'âœ…' if health['api'] else 'âŒ'}")
    print(f"   ML Service: {'âœ…' if health['ml'] else 'âŒ'}")
    
    if not all(health.values()):
        print("âŒ Some services are down. Please start them with: make up")
        return
    
    # 2. Inscription et connexion
    print("\n2. ğŸ” Authentication")
    username = f"demo_user_{int(time.time())}"
    email = f"{username}@example.com"
    password = "demopassword123"
    
    try:
        # Inscription
        user = client.register(email, username, password, "Demo User")
        print(f"   âœ… User registered: {user.get('username')}")
        
        # Connexion
        token = client.login(username, password)
        print(f"   âœ… Login successful")
        
        # Profil
        profile = client.get_profile()
        print(f"   âœ… Profile: {profile.get('full_name')} ({profile.get('role')})")
        
    except requests.exceptions.HTTPError as e:
        if "already registered" in str(e):
            print(f"   â„¹ï¸  User already exists, logging in...")
            client.login(username, password)
        else:
            raise
    
    # 3. CrÃ©er un projet
    print("\n3. ğŸ“ Project Creation")
    project = client.create_project(
        name=f"Demo Project {int(time.time())}",
        description="Projet de dÃ©monstration de l'API",
        tags=["demo", "test", "classification"]
    )
    project_id = project.get("id")
    
    # 4. Upload dataset
    print("\n4. ğŸ“Š Dataset Upload")
    dataset_file = create_sample_dataset()
    dataset = client.upload_dataset(
        file_path=dataset_file,
        name="Demo Dataset",
        description="Dataset de dÃ©monstration avec 4 features",
        project_id=project_id
    )
    dataset_id = dataset.get("id")
    
    # 5. CrÃ©er un modÃ¨le
    print("\n5. ğŸ¤– Model Creation")
    model = client.create_model(
        name="Demo Random Forest",
        model_type="classification",
        framework="scikit-learn",
        project_id=project_id,
        dataset_id=dataset_id,
        parameters={
            "n_estimators": 100,
            "max_depth": 10,
            "random_state": 42
        }
    )
    model_id = model.get("id")
    
    # 6. Simuler l'entraÃ®nement (dÃ©ploiement du modÃ¨le dÃ©mo)
    print("\n6. ğŸš€ Model Deployment")
    deployment = client.deploy_model(model_id)
    print(f"   âœ… Deployment status: {deployment.get('status')}")
    
    # 7. PrÃ©dictions
    print("\n7. ğŸ”® Predictions")
    
    # PrÃ©diction simple
    single_prediction = client.predict(
        model_id="demo_model_1",  # Utiliser le modÃ¨le de dÃ©mo prÃ©chargÃ©
        input_data={
            "feature1": 1.5,
            "feature2": 2.3,
            "feature3": 0.8,
            "feature4": 1.2
        },
        return_probabilities=True
    )
    
    print(f"   âœ… Single prediction: {single_prediction.get('prediction')}")
    print(f"   â±ï¸  Processing time: {single_prediction.get('processing_time'):.2f}ms")
    
    # PrÃ©dictions en lot
    batch_inputs = [
        {"feature1": 1.5, "feature2": 2.3, "feature3": 0.8, "feature4": 1.2},
        {"feature1": -0.5, "feature2": 1.1, "feature3": -1.2, "feature4": 0.8},
        {"feature1": 2.1, "feature2": 0.9, "feature3": 1.5, "feature4": 2.1}
    ]
    
    batch_predictions = client.batch_predict(
        model_id="demo_model_1",
        inputs=batch_inputs,
        return_probabilities=True
    )
    
    print(f"   âœ… Batch predictions: {len(batch_predictions.get('predictions', []))} results")
    print(f"   â±ï¸  Total time: {batch_predictions.get('total_processing_time'):.2f}ms")
    print(f"   âš¡ Avg per prediction: {batch_predictions.get('average_time_per_prediction'):.2f}ms")
    
    # 8. MÃ©triques
    print("\n8. ğŸ“Š Metrics")
    metrics = client.get_ml_metrics()
    
    global_metrics = metrics.get("global", {})
    print(f"   ğŸ• Uptime: {global_metrics.get('uptime_seconds', 0):.0f}s")
    print(f"   ğŸ“ˆ Total requests: {global_metrics.get('total_requests', 0)}")
    print(f"   ğŸ’¾ Cache hit rate: {global_metrics.get('cache_hit_rate', 0)*100:.1f}%")
    
    print("\nğŸ‰ DÃ©monstration terminÃ©e avec succÃ¨s!")
    print("\nğŸ“Š AccÃ©dez aux interfaces web:")
    print("   â€¢ API Docs: http://localhost:8000/docs")
    print("   â€¢ ML Docs:  http://localhost:8001/docs")
    print("   â€¢ Grafana:  http://localhost:3001 (admin/admin123)")
    print("   â€¢ Flower:   http://localhost:5555")

if __name__ == "__main__":
    main()